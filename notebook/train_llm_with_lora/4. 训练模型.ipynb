{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c335775-4312-4893-801d-bd67e73d7cef",
   "metadata": {},
   "source": [
    "### 运行方法\n",
    "- [参考页面](https://qwen.readthedocs.io/zh-cn/latest/training/SFT/llama_factory.html)\n",
    "1. 进入llamafactor目录\n",
    "```bash\n",
    "cd LLaMA-Factory\n",
    "```\n",
    "2. 将模型放到相关目录，比如download文件夹，这样你的模型路径就是`download/Qwen2.5-7B-Instruct`\n",
    "\n",
    "3. 将数据集的两个json文件放到LaMA-Factory项目的data目录。\n",
    "\n",
    "4. 修改data/dataset_info.json文件，将data_info.json文件的内容粘贴合并进去。\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"identity\": {\n",
    "    \"file_name\": \"identity.json\"\n",
    "  },\n",
    "  ....\n",
    "  \"starcoder_python\": {\n",
    "    \"hf_hub_url\": \"bigcode/starcoderdata\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/starcoderdata\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"content\"\n",
    "    },\n",
    "    \"folder\": \"python\"\n",
    "  },\n",
    "  \"my_dataset\": {\n",
    "    \"file_name\": \"my_dataset.json\",\n",
    "    \"formatting\": \"sharegpt\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"messages\"\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"role_tag\": \"role\",\n",
    "      \"content_tag\": \"content\",\n",
    "      \"user_tag\": \"user\",\n",
    "      \"assistant_tag\": \"assistant\",\n",
    "      \"system_tag\": \"system\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "6. 输出路径可以为output/Qwen2.5-7B-Instruct\n",
    "```bash\n",
    "mkdir -p output/Qwen2.5-7B-Instruct\n",
    "```\n",
    "\n",
    "6. 开一个screen命令，挂后台方便。\n",
    "```bash\n",
    "# 安装screen\n",
    "sudo apt install screen\n",
    "# 开一个screen 后台\n",
    "screen -S train\n",
    "```\n",
    "\n",
    "7. 运行下面的命令开始训练，`cutoff_len`为最大token数，建议设置为2的指数倍，这个参数根据第一步的数据分析得到。\n",
    "- `my_dataset`即第三步自定义构建的数据集, `>>train.log`将训练过程放到train.log文件。\n",
    "- `CUDA_VISIBLE_DEVICES=0`用于指定卡0跑模型，如果需要多卡，可以参考官方的教程，加一些并行参数。\n",
    "- 参数配置可以参考官方给的sft配置文件。[链接](https://github.com/QwenLM/Qwen2.5/blob/main/examples/llama-factory/qwen2-7b-lora-sft.yaml)\n",
    "- 创建一个bash.sh文件，将运行参数写进去。\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0 python3 src/train.py \\\n",
    "    --stage sft \\\n",
    "    --lora_rank 16 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target all \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --learning_rate 1.0e-4 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --do_train \\\n",
    "    --use_fast_tokenizer \\\n",
    "    --model_name_or_path download/Qwen2.5-7B-Instruct \\\n",
    "    --dataset my_dataset \\\n",
    "    --template qwen \\\n",
    "    --finetuning_type lora \\\n",
    "    --output_dir output/Qwen2.5-7B-Instruct \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ddp_timeout 180000000 \\\n",
    "    --logging_steps 1 \\\n",
    "    --cutoff_len 1024 \\\n",
    "    --save_steps 1000 \\\n",
    "    --plot_loss \\\n",
    "    --bf16 \n",
    "```\n",
    "- 执行这个bash文件，运行命令如下：\n",
    "```bash\n",
    "./bash.sh > train.log  2>&1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b750b2-16cc-47b5-8088-b04ab9ac12f8",
   "metadata": {},
   "source": [
    "### 压缩lora目录文件为zip（可选）\n",
    "```bash\n",
    "cd output/Qwen2.5-7B-Instruct\n",
    "zip -j lora.zip *\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdb6ce-eed0-47f1-8850-e72d35a855e4",
   "metadata": {},
   "source": [
    "### 合并lora文件到模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382ef03-1c2e-4c68-9007-846653bd146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli export \\\n",
    "    --model_name_or_path download/Qwen2.5-7B-Instruct \\\n",
    "    --adapter_name_or_path output/Qwen2.5-7B-Instruct \\\n",
    "    --template qwen \\\n",
    "    --finetuning_type lora \\\n",
    "    --export_dir output/Qwen2.5-7B-Instruct-Lora-Merge \\\n",
    "    --export_size 2 \\\n",
    "    --export_legacy_format False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
